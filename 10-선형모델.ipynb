{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(boston.keys())  # data, feature_names : 학습데이터, target : 목적(label), DESCR : 설명서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설명서의 확인\n",
    "print(boston['DESCR'])\n",
    "# RM : 방 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 살펴보자.\n",
    "# 판다스 데이터로 정리해보자.\n",
    "import pandas as pd\n",
    "boston_df = pd.DataFrame(boston['data'],  # 학습 데이터\n",
    "                        columns=boston['feature_names']  # 특징\n",
    "                        )\n",
    "boston_df\n",
    "# 특징 13개 있음\n",
    "\n",
    "# target이 나와있지 않음. 옆에 붙여주자.\n",
    "boston_df['TARGET'] = boston['target']\n",
    "boston_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 RM, TARGET의 관계를 파악해보자.\n",
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "X_rooms = boston['data'][:, 5]  # 학습 데이터의 RM 변수의 전체 행, 5번 열\n",
    "# 산점도 그리기\n",
    "plt.scatter(X_rooms, boston['target'])\n",
    "plt.xlabel(\"No of rooms\")\n",
    "plt.ylabel(\"Price/1000 (&)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형 회귀 모델의 생성\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "# 학습 진행\n",
    "reg.fit(X_rooms.reshape(-1, 1),  # 학습데이터\n",
    "        boston['target'])  # 라벨 데이터\n",
    "# 최종 목적은 회귀 선을 위한 가중치와 절편을 구하는 것\n",
    "print(\"모델의 가중치:\", reg.coef_)\n",
    "print(\"모델의 절편:\", reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 학습 데이터와 회귀선\n",
    "import numpy as np\n",
    "pred_space = np.linspace(\n",
    "    min(X_rooms), max(X_rooms)\n",
    ").reshape(-1, 1)\n",
    "\n",
    "# 산점도 그리기\n",
    "plt.scatter(X_rooms,  # x축\n",
    "           boston['target'])  # y축\n",
    "\n",
    "# 회귀선\n",
    "plt.plot(pred_space,  # x축\n",
    "        reg.predict(pred_space),\n",
    "        color=\"red\"\n",
    "        )  # 우리 모델의 예측값\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boston 데이터셋 모든 특성을 이용한 예측\n",
    "# 학습 데이터, 테스트 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    boston['data'], boston['target'],\n",
    "    test_size=0.3,   # 테스트 데이터 셋 사이즈 30%\n",
    "    random_state=42  # 재현성 확보를 위한 랜덤 시드\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 진행\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train, y_train)  # 학습 데이터와 학습 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치와 절편\n",
    "print(\"가중치:\", reg_all.coef_)\n",
    "print(\"절편:\", reg_all.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 검증\n",
    "print(\"훈련 세트 점수: {:.2f}\".format(reg_all.score(X_train, y_train)))  # 학습 데이터\n",
    "print(\"테스트 세트 점수: {:.2f}\".format(reg_all.score(X_test, y_test)))  # 테스트 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 보스턴 데이터셋의 첫번째 데이터와 타겟\n",
    "print(\"데이터셋 관측치:\", boston['data'][0])\n",
    "print(\"데이터셋label:\", boston['target'][0])\n",
    "\n",
    "# 모델이 예측한 예측치\n",
    "reg_all.predict(boston['data'][0].reshape(1, 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge 회귀\n",
    "# L2 규제를 사용하여 특성의 계수(기울기)를 최소화하는 모델\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=0.1,  # 알파 계수(규제)\n",
    "             normalize=True)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "print(\"Ridge 훈련 세트 점수: {:.2f}\".format(ridge.score(X_train, y_train)))  # 학습 데이터\n",
    "print(\"Ridge 테스트 세트 점수: {:.2f}\".format(ridge.score(X_test, y_test)))  # 테스트 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso 회귀\n",
    "# L1 규제를 사용하고 특정 계수를 0으로 만들어서 영향을 없애는 효과(특성 선택)\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=0.1,  # 규제 계수\n",
    "             normalize=True)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "print(\"Lasso 훈련 세트 점수: {:.2f}\".format(lasso.score(X_train, y_train)))  # 학습 데이터\n",
    "print(\"Lasso 테스트 세트 점수: {:.2f}\".format(lasso.score(X_test, y_test)))  # 테스트 데이터\n",
    "print(\"계수:\", lasso.coef_)\n",
    "# Lasso 회귀는 특정 계수를 0으로 만든다.\n",
    "print(\"사용된 특성의 갯수:\", np.sum(lasso.coef_ != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류용 선형 모델\n",
    "# LinearRegression, SVC(서포트 벡터 머신)\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer['data'], cancer['target'],\n",
    "    stratify=cancer.target,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "print(\"LogReg 훈련 세트 점수: {:.2f}\".format(logreg.score(X_train, y_train)))\n",
    "print(\"LogReg 테스트 세트 점수: {:.2f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC(서포트 벡터 머신) : 회귀, 분류 양쪽 모두에 사용\n",
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC().fit(X_train, y_train)\n",
    "print(\"SVC 훈련 세트 점수: {:.2f}\".format(svc.score(X_train, y_train)))\n",
    "print(\"SVC 테스트 세트 점수: {:.2f}\".format(svc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 규제 강도에 따른 정확도\n",
    "# 과적합 방지\n",
    "# 선형 회귀 모델에 규제 강도별 점수\n",
    "logreg100 = LogisticRegression(C=100).fit(X_train, y_train)    # 규제 C = 100\n",
    "logreg = LogisticRegression().fit(X_train, y_train)            # 규제 C = 1\n",
    "logreg001 = LogisticRegression(C=0.01).fit(X_train, y_train)   # 규제 C = 0.01\n",
    "\n",
    "for c, model in zip([100, 1, 0.01], [logreg100, logreg, logreg001]):\n",
    "    print(\"C={}\".format(c))\n",
    "    print(\"훈련 세트 점수: {:.2f}\".format(model.score(X_train, y_train)))\n",
    "    print(\"테스트 세트 점수: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "# 기본적으로는 L2규제(Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 규제 방식에 따른 정확도 확인\n",
    "l1lr100 = LogisticRegression(C=100, \n",
    "                             solver=\"saga\", \n",
    "                             penalty=\"l1\").fit(X_train, y_train)\n",
    "l1lr = LogisticRegression(solver=\"saga\", \n",
    "                          penalty=\"l1\").fit(X_train, y_train)\n",
    "l1lr001 = LogisticRegression(C=0.01, \n",
    "                             solver=\"saga\", \n",
    "                             penalty=\"l1\").fit(X_train, y_train)\n",
    "\n",
    "for c, model in zip([100, 1, 0.01], [l1lr100, l1lr, l1lr001]):\n",
    "    print(\"L1 규제={}\".format(c))\n",
    "    print(\"훈련 세트 점수: {:.2f}\".format(model.score(X_train, y_train)))\n",
    "    print(\"테스트 세트 점수: {:.2f}\".format(model.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
